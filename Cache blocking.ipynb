{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47386a6",
   "metadata": {},
   "source": [
    "Concept to know before start\n",
    "- Registers (fastest)\n",
    "- L1 cache (~32 KB)\n",
    "- L2 cache\n",
    "- RAM (slow)\n",
    "\n",
    "Also:\n",
    "- If working data fits inside L1 cache → FAST.\n",
    "- If not → cache misses → SLOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ffae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No cache reuse  - Baseline implementation\n",
    "import numpy as np\n",
    "import time\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def no_blocking(array_data, nruns):\n",
    "    n = len(array_data)\n",
    "\n",
    "    i = 0\n",
    "    while i < nruns:\n",
    "        j = 0\n",
    "        while j < n:\n",
    "            array_data[j] = 2.3 * array_data[j] + 1.2\n",
    "            j += 1\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d9cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache blocked implementation\n",
    "@njit\n",
    "def cache_blocking(array_data, nruns, l1size):\n",
    "    n = len(array_data)\n",
    "\n",
    "    blockstart = 0\n",
    "\n",
    "    while blockstart < n:\n",
    "\n",
    "        # operate many times on SAME BLOCK\n",
    "        b = 0\n",
    "        while b < nruns:\n",
    "\n",
    "            j = 0\n",
    "            while j < l1size and (blockstart + j) < n:\n",
    "                idx = blockstart + j\n",
    "                array_data[idx] = 2.3 * array_data[idx] + 1.2\n",
    "                j += 1\n",
    "\n",
    "            b += 1\n",
    "\n",
    "        blockstart += l1size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bcb1510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No blocking: 7.8998730182647705\n",
      "Cache blocking: 0.9585721492767334\n"
     ]
    }
   ],
   "source": [
    "# Measuring the performance\n",
    "N = 5000000\n",
    "NRUNS = 2000\n",
    "\n",
    "A1 = np.random.rand(N)\n",
    "A2 = A1.copy()\n",
    "\n",
    "# compile first\n",
    "no_blocking(A1, 1)\n",
    "cache_blocking(A2, 1, 1024)\n",
    "\n",
    "start = time.time()\n",
    "no_blocking(A1, NRUNS)\n",
    "print(\"No blocking:\", time.time()-start)\n",
    "\n",
    "start = time.time()\n",
    "cache_blocking(A2, NRUNS, 1024)\n",
    "print(\"Cache blocking:\", time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d679c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1size=   128  time=0.8443634510  time/op=8.44e-11\n",
      "l1size=   256  time=0.8876249790  time/op=8.88e-11\n",
      "l1size=   512  time=0.8577971458  time/op=8.58e-11\n",
      "l1size=  1024  time=0.8002614975  time/op=8.00e-11\n",
      "l1size=  2048  time=0.8402786255  time/op=8.40e-11\n",
      "l1size=  4096  time=0.8303656578  time/op=8.30e-11\n",
      "l1size=  8192  time=1.2071485519  time/op=1.21e-10\n",
      "l1size= 16384  time=1.3940382004  time/op=1.39e-10\n"
     ]
    }
   ],
   "source": [
    "# Now we simulate increasing working-set size\n",
    "sizes = [128, 256, 512, 1024, 2048, 4096, 8192, 16384]\n",
    "ops = N * NRUNS\n",
    "for l1 in sizes:\n",
    "    A2 = A1.copy()\n",
    "\n",
    "    start = time.time()\n",
    "    cache_blocking(A2, NRUNS, l1)\n",
    "    t = time.time() - start\n",
    "\n",
    "    time_per_op = t / ops\n",
    "\n",
    "    print(f\"l1size={l1:6d}  time={t:.10f}  time/op={time_per_op:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedee7f3",
   "metadata": {},
   "source": [
    "*Note:*\n",
    "Making the l1size parameter bigger means the computer operates on more data.  Operation time remains roughly constant for block sizes of about 4096 elements since the working set fits into the 32 KB L1 cache. When the block size exceeds this limit, time per operation increases a lot, suggesting that data no longer fits in L1 cache, and must go to the lower levels of cache.\n",
    "\n",
    "By confirming the cache hierarchy model, this behavior also shows that cache blocking enhances performance, as it ensures reused data remains in the fastest cache level. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
